{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b683eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-face\n",
      "  Downloading azure_cognitiveservices_vision_face-0.6.0-py2.py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.7/67.7 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     ---------------------------------------- 85.4/85.4 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2022.9.14)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.7/41.7 kB ? eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting azure-core>=1.24.0\n",
      "  Downloading azure_core-1.26.3-py3-none-any.whl (174 kB)\n",
      "     -------------------------------------- 174.5/174.5 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.28.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-common, oauthlib, isodate, requests-oauthlib, azure-core, msrest, azure-cognitiveservices-vision-face\n",
      "Successfully installed azure-cognitiveservices-vision-face-0.6.0 azure-common-1.1.28 azure-core-1.26.3 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b3497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: 7807c6d6-df0a-4819-9520-cab94d8240c8\n",
      "face 1dcc1a05-8daf-4a9b-bf82-7c36869a5481 added to person 838e3133-2555-40fc-8fda-19b0c374f4bc\n",
      "face a9fab1bc-4f7b-4b3e-9868-02172cc59e3e added to person 838e3133-2555-40fc-8fda-19b0c374f4bc\n",
      "face 6897ef23-0f50-47d3-88ca-c99c7f4986b5 added to person dc4a3182-1935-473d-bc00-c79b6c6045fe\n",
      "face f785edd6-71f5-4a28-9516-307d02146885 added to person dc4a3182-1935-473d-bc00-c79b6c6045fe\n",
      "face be2aa2a1-c6de-487a-855c-778e766d6435 added to person 0d736d5d-65da-4caf-bc9b-dd7319f3e282\n",
      "face 73ae3ed4-ef75-47aa-a196-6992e933b79c added to person 0d736d5d-65da-4caf-bc9b-dd7319f3e282\n",
      "pg resource is 7807c6d6-df0a-4819-9520-cab94d8240c8\n",
      "<msrest.pipeline.ClientRawResponse object at 0x000002119CBCC850>\n",
      "Training status: succeeded.\n",
      "\n",
      "Pausing for 10 seconds to avoid triggering rate limit on free account...\n",
      "Identifying faces in image\n",
      "Person is identified for face ID b79fccb4-95b5-468f-a702-dfe4535cd5e4 in image, with a confidence of 0.96725.\n",
      "verification result: True. confidence: 0.96725\n",
      "Person is identified for face ID 9daab9b0-c17c-444a-ac76-a6ff8c42193b in image, with a confidence of 0.96921.\n",
      "verification result: True. confidence: 0.96921\n",
      "No person identified for face ID 8e687b47-9a88-4f6e-ad2f-4264b9cb0a10 in image.\n",
      "Person is identified for face ID cad93b10-48fa-4269-b80c-83ed68c54a9d in image, with a confidence of 0.92886.\n",
      "verification result: True. confidence: 0.92886\n",
      "\n",
      "End of quickstart.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition\n",
    "\n",
    "\n",
    "# This key will serve all examples in this document.\n",
    "KEY = \"2bf3fa20e6d94740af639c24f5c8c3ff\"\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"https://facial-recognition-poc.cognitiveservices.azure.com/\"\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/'\n",
    "\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Child\")\n",
    "\n",
    "'''\n",
    "Detect faces and register them to each person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory (TBD pull from web instead)\n",
    "woman_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Mom1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Mom2.jpg\"]\n",
    "man_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Dad1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Dad2.jpg\"]\n",
    "child_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Son1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Son2.jpg\"]\n",
    "\n",
    "# Add to woman person\n",
    "for image in woman_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, woman.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, woman.person_id))\n",
    "\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "# Add to man person\n",
    "for image in man_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, man.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, man.person_id))\n",
    "\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "# Add to child person\n",
    "for image in child_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            print(\"{} has insufficient quality\".format(face))\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, child.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, child.person_id))\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "\n",
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)\n",
    "\n",
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/identification1.jpg\"\n",
    "\n",
    "print('Pausing for 10 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (10)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_url(test_image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in image')\n",
    "if not results:\n",
    "    print('No person identified in the person group')\n",
    "for identifiedFace in results:\n",
    "    if len(identifiedFace.candidates) > 0:\n",
    "        print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "        # Verify faces\n",
    "        verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "        print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "    else:\n",
    "        print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))\n",
    " \n",
    "\n",
    "print()\n",
    "print('End of quickstart.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16db277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
